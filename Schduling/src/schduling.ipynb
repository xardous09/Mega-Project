{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e822917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('manufacturing_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e37f77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetime columns\n",
    "datetime_cols = ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']\n",
    "for col in datetime_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce9eee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate durations (in hours)\n",
    "df['Calculated_Scheduled_Duration'] = (df['Scheduled_End'] - df['Scheduled_Start']).dt.total_seconds() / 3600\n",
    "df['Calculated_Actual_Duration'] = (df['Actual_End'] - df['Actual_Start']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4dd4ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded and preprocessed successfully.\n",
      "üîç Total jobs: 1000\n",
      "üõ†Ô∏è Unique machines: 5\n",
      "\n",
      "üßæ Sample preview:\n",
      "  Job_ID Machine_ID Operation_Type  Material_Used  Processing_Time  \\\n",
      "0   J001        M01       Grinding           3.17               76   \n",
      "1   J002        M01       Grinding           3.35               79   \n",
      "2   J003        M04       Additive           2.29               56   \n",
      "3   J004        M04       Grinding           1.76              106   \n",
      "4   J005        M01          Lathe           1.90               46   \n",
      "\n",
      "   Energy_Consumption  Machine_Availability     Scheduled_Start  \\\n",
      "0               11.42                    96 2023-03-18 08:00:00   \n",
      "1                6.61                    84 2023-03-18 08:10:00   \n",
      "2               11.11                    92 2023-03-18 08:20:00   \n",
      "3               12.50                    95 2023-03-18 08:30:00   \n",
      "4                8.13                    88 2023-03-18 08:40:00   \n",
      "\n",
      "        Scheduled_End        Actual_Start          Actual_End Job_Status  \\\n",
      "0 2023-03-18 09:16:00 2023-03-18 08:05:00 2023-03-18 09:21:00  Completed   \n",
      "1 2023-03-18 09:29:00 2023-03-18 08:20:00 2023-03-18 09:39:00    Delayed   \n",
      "2 2023-03-18 09:16:00                 NaT                 NaT     Failed   \n",
      "3 2023-03-18 10:16:00 2023-03-18 08:35:00 2023-03-18 10:21:00  Completed   \n",
      "4 2023-03-18 09:26:00 2023-03-18 08:42:00 2023-03-18 09:28:00  Completed   \n",
      "\n",
      "  Optimization_Category  Calculated_Scheduled_Duration  \\\n",
      "0   Moderate Efficiency                       1.266667   \n",
      "1        Low Efficiency                       1.316667   \n",
      "2        Low Efficiency                       0.933333   \n",
      "3   Moderate Efficiency                       1.766667   \n",
      "4       High Efficiency                       0.766667   \n",
      "\n",
      "   Calculated_Actual_Duration  \n",
      "0                    1.266667  \n",
      "1                    1.316667  \n",
      "2                         NaN  \n",
      "3                    1.766667  \n",
      "4                    0.766667  \n"
     ]
    }
   ],
   "source": [
    "# Display basic insights\n",
    "print(\"‚úÖ Data loaded and preprocessed successfully.\")\n",
    "print(f\"üîç Total jobs: {len(df)}\")\n",
    "print(f\"üõ†Ô∏è Unique machines: {df['Machine_ID'].nunique()}\")\n",
    "print(\"\\nüßæ Sample preview:\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbac0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data for further modules\n",
    "df.to_csv('preprocessed_job_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbbc010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "df = pd.read_csv('preprocessed_job_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1a1a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find a spare machine\n",
    "def find_spare_machine(operation_type, excluded_machine):\n",
    "    candidates = df[\n",
    "        (df['Operation_Type'] == operation_type) &\n",
    "        (df['Machine_Availability'] > 90) &\n",
    "        (df['Machine_ID'] != excluded_machine)\n",
    "    ]\n",
    "    if not candidates.empty:\n",
    "        # Prefer lowest energy consumption\n",
    "        return candidates.sort_values('Energy_Consumption').iloc[0]['Machine_ID']\n",
    "    return None\n",
    "\n",
    "# Initialize results list\n",
    "scheduled_jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "935b6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each job\n",
    "for index, row in df.iterrows():\n",
    "    job_id = row['Job_ID']\n",
    "    original_machine = row['Machine_ID']\n",
    "    operation = row['Operation_Type']\n",
    "    duration = row['Processing_Time']\n",
    "    availability = row['Machine_Availability']\n",
    "    \n",
    "    # Schedule Start fallback if missing\n",
    "    start_time = pd.to_datetime(row['Scheduled_Start']) if pd.notnull(row['Scheduled_Start']) else pd.Timestamp.now()\n",
    "\n",
    "    if availability > 90:\n",
    "        status = f\"Assigned to {original_machine}\"\n",
    "        end_time = start_time + pd.to_timedelta(duration, unit='h')\n",
    "        machine_used = original_machine\n",
    "    else:\n",
    "        spare_machine = find_spare_machine(operation, original_machine)\n",
    "        if spare_machine:\n",
    "            status = f\"üîÅ Reassigned to spare machine {spare_machine}\"\n",
    "            end_time = start_time + pd.to_timedelta(duration, unit='h')\n",
    "            machine_used = spare_machine\n",
    "        else:\n",
    "            status = f\" No available machine for {operation}\"\n",
    "            end_time = None\n",
    "            machine_used = None\n",
    "\n",
    "    scheduled_jobs.append({\n",
    "        'Job_ID': job_id,\n",
    "        'Assigned_Machine': machine_used,\n",
    "        'Scheduled_Start': start_time,\n",
    "        'Estimated_End': end_time,\n",
    "        'Status': status\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3271cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóìÔ∏è Job Scheduling Summary:\n",
      "  Job_ID Assigned_Machine     Scheduled_Start       Estimated_End  \\\n",
      "0   J001              M01 2023-03-18 08:00:00 2023-03-21 12:00:00   \n",
      "1   J002              M04 2023-03-18 08:10:00 2023-03-21 15:10:00   \n",
      "2   J003              M04 2023-03-18 08:20:00 2023-03-20 16:20:00   \n",
      "3   J004              M04 2023-03-18 08:30:00 2023-03-22 18:30:00   \n",
      "4   J005              M04 2023-03-18 08:40:00 2023-03-20 06:40:00   \n",
      "5   J006              M04 2023-03-18 08:50:00 2023-03-22 12:50:00   \n",
      "6   J007              M03 2023-03-18 09:00:00 2023-03-19 07:00:00   \n",
      "7   J008              M05 2023-03-18 09:10:00 2023-03-21 16:10:00   \n",
      "8   J009              M03 2023-03-18 09:20:00 2023-03-20 03:20:00   \n",
      "9   J010              M01 2023-03-18 09:30:00 2023-03-19 12:30:00   \n",
      "\n",
      "                              Status  \n",
      "0                    Assigned to M01  \n",
      "1  üîÅ Reassigned to spare machine M04  \n",
      "2                    Assigned to M04  \n",
      "3                    Assigned to M04  \n",
      "4  üîÅ Reassigned to spare machine M04  \n",
      "5  üîÅ Reassigned to spare machine M04  \n",
      "6  üîÅ Reassigned to spare machine M03  \n",
      "7                    Assigned to M05  \n",
      "8  üîÅ Reassigned to spare machine M03  \n",
      "9                    Assigned to M01  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame\n",
    "schedule_df = pd.DataFrame(scheduled_jobs)\n",
    "\n",
    "# Show results\n",
    "print(\"üóìÔ∏è Job Scheduling Summary:\")\n",
    "print(schedule_df[['Job_ID', 'Assigned_Machine', 'Scheduled_Start', 'Estimated_End', 'Status']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81d0b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for visualization\n",
    "schedule_df.to_csv('job_schedule_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b711c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize machine failure history tracker\n",
    "machine_failure_history = defaultdict(list)\n",
    "breakdown_alerts = []\n",
    "\n",
    "# Define threshold values\n",
    "FAILURE_THRESHOLD = 2  # e.g., 2 consecutive failures\n",
    "FAILURE_WINDOW = 5\n",
    "FAILURE_RATIO = 0.6    # e.g., 60% failure rate in recent 5 jobs\n",
    "\n",
    "# Sort by Scheduled_Start to track in chronological order\n",
    "df = df.sort_values(by='Scheduled_Start')\n",
    "\n",
    "# Track failures\n",
    "for idx, row in df.iterrows():\n",
    "    machine = row['Machine_ID']\n",
    "    status = row['Job_Status']\n",
    "    job_id = row['Job_ID']\n",
    "    start_time = row['Scheduled_Start']\n",
    "\n",
    "    # Record status\n",
    "    machine_failure_history[machine].append(status)\n",
    "\n",
    "    # Get recent statuses (last 5 jobs max)\n",
    "    recent_statuses = machine_failure_history[machine][-FAILURE_WINDOW:]\n",
    "\n",
    "    # Check for consecutive failures\n",
    "    consecutive_failures = all(s == 'Failed' for s in recent_statuses[-FAILURE_THRESHOLD:])\n",
    "\n",
    "    # Check failure ratio\n",
    "    failure_ratio = recent_statuses.count('Failed') / len(recent_statuses)\n",
    "\n",
    "    # Raise alert if either threshold is met\n",
    "    if consecutive_failures or failure_ratio >= FAILURE_RATIO:\n",
    "        alert_msg = f\"‚ö†Ô∏è ALERT: {machine} is unreliable! ({failure_ratio*100:.0f}% failures in recent jobs)\"\n",
    "        alert_detail = {\n",
    "            \"Machine_ID\": machine,\n",
    "            \"Affected_Job\": job_id,\n",
    "            \"Alert_Time\": start_time,\n",
    "            \"Alert_Message\": alert_msg\n",
    "        }\n",
    "        breakdown_alerts.append(alert_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54fcc1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Breakdown Alerts üö®\n",
      "   Machine_ID Affected_Job           Alert_Time  \\\n",
      "0         M04         J003  2023-03-18 08:20:00   \n",
      "1         M04         J175  2023-03-19 13:00:00   \n",
      "2         M04         J205  2023-03-19 18:00:00   \n",
      "3         M03         J222  2023-03-19 20:50:00   \n",
      "4         M03         J239  2023-03-19 23:40:00   \n",
      "5         M04         J342  2023-03-20 16:50:00   \n",
      "6         M01         J514  2023-03-21 21:30:00   \n",
      "7         M01         J516  2023-03-21 21:50:00   \n",
      "8         M01         J525  2023-03-21 23:20:00   \n",
      "9         M01         J527  2023-03-21 23:40:00   \n",
      "10        M03         J573  2023-03-22 07:20:00   \n",
      "11        M05         J585  2023-03-22 09:20:00   \n",
      "12        M05         J591  2023-03-22 10:20:00   \n",
      "13        M05         J594  2023-03-22 10:50:00   \n",
      "14        M03         J608  2023-03-22 13:10:00   \n",
      "15        M03         J609  2023-03-22 13:20:00   \n",
      "16        M01         J611  2023-03-22 13:40:00   \n",
      "17        M03         J612  2023-03-22 13:50:00   \n",
      "18        M03         J613  2023-03-22 14:00:00   \n",
      "19        M01         J616  2023-03-22 14:30:00   \n",
      "20        M01         J617  2023-03-22 14:40:00   \n",
      "21        M03         J622  2023-03-22 15:30:00   \n",
      "22        M04         J637  2023-03-22 18:00:00   \n",
      "23        M02         J701  2023-03-23 04:40:00   \n",
      "24        M03         J705  2023-03-23 05:20:00   \n",
      "25        M02         J717  2023-03-23 07:20:00   \n",
      "26        M02         J721  2023-03-23 08:00:00   \n",
      "27        M01         J753  2023-03-23 13:20:00   \n",
      "28        M01         J932  2023-03-24 19:10:00   \n",
      "\n",
      "                                        Alert_Message  \n",
      "0   ‚ö†Ô∏è ALERT: M04 is unreliable! (100% failures in...  \n",
      "1   ‚ö†Ô∏è ALERT: M04 is unreliable! (60% failures in ...  \n",
      "2   ‚ö†Ô∏è ALERT: M04 is unreliable! (40% failures in ...  \n",
      "3   ‚ö†Ô∏è ALERT: M03 is unreliable! (40% failures in ...  \n",
      "4   ‚ö†Ô∏è ALERT: M03 is unreliable! (60% failures in ...  \n",
      "5   ‚ö†Ô∏è ALERT: M04 is unreliable! (40% failures in ...  \n",
      "6   ‚ö†Ô∏è ALERT: M01 is unreliable! (40% failures in ...  \n",
      "7   ‚ö†Ô∏è ALERT: M01 is unreliable! (60% failures in ...  \n",
      "8   ‚ö†Ô∏è ALERT: M01 is unreliable! (60% failures in ...  \n",
      "9   ‚ö†Ô∏è ALERT: M01 is unreliable! (60% failures in ...  \n",
      "10  ‚ö†Ô∏è ALERT: M03 is unreliable! (40% failures in ...  \n",
      "11  ‚ö†Ô∏è ALERT: M05 is unreliable! (40% failures in ...  \n",
      "12  ‚ö†Ô∏è ALERT: M05 is unreliable! (60% failures in ...  \n",
      "13  ‚ö†Ô∏è ALERT: M05 is unreliable! (60% failures in ...  \n",
      "14  ‚ö†Ô∏è ALERT: M03 is unreliable! (40% failures in ...  \n",
      "15  ‚ö†Ô∏è ALERT: M03 is unreliable! (60% failures in ...  \n",
      "16  ‚ö†Ô∏è ALERT: M01 is unreliable! (40% failures in ...  \n",
      "17  ‚ö†Ô∏è ALERT: M03 is unreliable! (80% failures in ...  \n",
      "18  ‚ö†Ô∏è ALERT: M03 is unreliable! (80% failures in ...  \n",
      "19  ‚ö†Ô∏è ALERT: M01 is unreliable! (60% failures in ...  \n",
      "20  ‚ö†Ô∏è ALERT: M01 is unreliable! (60% failures in ...  \n",
      "21  ‚ö†Ô∏è ALERT: M03 is unreliable! (60% failures in ...  \n",
      "22  ‚ö†Ô∏è ALERT: M04 is unreliable! (40% failures in ...  \n",
      "23  ‚ö†Ô∏è ALERT: M02 is unreliable! (40% failures in ...  \n",
      "24  ‚ö†Ô∏è ALERT: M03 is unreliable! (40% failures in ...  \n",
      "25  ‚ö†Ô∏è ALERT: M02 is unreliable! (60% failures in ...  \n",
      "26  ‚ö†Ô∏è ALERT: M02 is unreliable! (60% failures in ...  \n",
      "27  ‚ö†Ô∏è ALERT: M01 is unreliable! (60% failures in ...  \n",
      "28  ‚ö†Ô∏è ALERT: M01 is unreliable! (40% failures in ...  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame for display\n",
    "breakdown_alerts_df = pd.DataFrame(breakdown_alerts)\n",
    "print(\"üö® Breakdown Alerts üö®\")\n",
    "print(breakdown_alerts_df if not breakdown_alerts_df.empty else \"No critical machine issues detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da3b0d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plyer\n",
      "  Downloading plyer-2.1.0-py2.py3-none-any.whl.metadata (61 kB)\n",
      "Downloading plyer-2.1.0-py2.py3-none-any.whl (142 kB)\n",
      "Installing collected packages: plyer\n",
      "Successfully installed plyer-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install plyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fad38880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyer import notification\n",
    "\n",
    "# Send alert for each breakdown\n",
    "for alert in breakdown_alerts:\n",
    "    notification.notify(\n",
    "        title=\"‚ö†Ô∏è Machine Breakdown Alert\",\n",
    "        message=f\"{alert['Alert_Message']} | Job: {alert['Affected_Job']} | Time: {alert['Alert_Time']}\",\n",
    "        timeout=10  # seconds\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "652b5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_replacement(machine_id, job_row, df):\n",
    "    same_type_machines = df[\n",
    "        (df['Operation_Type'] == job_row['Operation_Type']) &\n",
    "        (df['Machine_ID'] != machine_id) &\n",
    "        (df['Machine_Availability'] > 80)  # arbitrary availability threshold\n",
    "    ].sort_values(by=['Machine_Availability', 'Energy_Consumption'], ascending=[False, True])\n",
    "\n",
    "    if not same_type_machines.empty:\n",
    "        return same_type_machines.iloc[0]['Machine_ID']\n",
    "    else:\n",
    "        return \"No optimal replacement found\"\n",
    "\n",
    "# Add replacement suggestion to alert\n",
    "for alert in breakdown_alerts:\n",
    "    job_row = df[df['Job_ID'] == alert['Affected_Job']].iloc[0]\n",
    "    replacement = recommend_replacement(alert['Machine_ID'], job_row, df)\n",
    "    alert['Suggested_Replacement'] = replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d0fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended replacement for M04: M01\n",
      "Recommended replacement for M04: M02\n",
      "Recommended replacement for M04: M03\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M04: M01\n",
      "Recommended replacement for M01: M05\n",
      "Recommended replacement for M01: M04\n",
      "Recommended replacement for M01: M03\n",
      "Recommended replacement for M01: M03\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M05: M02\n",
      "Recommended replacement for M05: M01\n",
      "Recommended replacement for M05: M04\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M01: M02\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M03: M01\n",
      "Recommended replacement for M01: M04\n",
      "Recommended replacement for M01: M04\n",
      "Recommended replacement for M03: M01\n",
      "Recommended replacement for M04: M01\n",
      "Recommended replacement for M02: M01\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M02: M04\n",
      "Recommended replacement for M02: M03\n",
      "Recommended replacement for M01: M05\n",
      "Recommended replacement for M01: M02\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from plyer import notification\n",
    "\n",
    "\n",
    "class JobSchedulingModel:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.machine_failure_history = defaultdict(list)\n",
    "        self.breakdown_alerts = []\n",
    "\n",
    "    def send_desktop_alert(self, message):\n",
    "        notification.notify(\n",
    "            title=\"Machine Breakdown Alert\",\n",
    "            message=message,\n",
    "            timeout=10\n",
    "        )\n",
    "\n",
    "    def recommend_replacement(self, machine_id, job_row):\n",
    "        same_type_machines = self.df[\n",
    "            (self.df['Operation_Type'] == job_row['Operation_Type']) &\n",
    "            (self.df['Machine_ID'] != machine_id) &\n",
    "            (self.df['Machine_Availability'] > 80)  # arbitrary availability threshold\n",
    "        ].sort_values(by=['Machine_Availability', 'Energy_Consumption'], ascending=[False, True])\n",
    "\n",
    "        if not same_type_machines.empty:\n",
    "            return same_type_machines.iloc[0]['Machine_ID']\n",
    "        else:\n",
    "            return \"No optimal replacement found\"\n",
    "\n",
    "    def track_machine_failures_and_recommendation(self):\n",
    "        for idx, row in self.df.iterrows():\n",
    "            machine = row['Machine_ID']\n",
    "            status = row['Job_Status']\n",
    "            job_id = row['Job_ID']\n",
    "            start_time = row['Scheduled_Start']\n",
    "\n",
    "            # Track failures for the machine\n",
    "            self.machine_failure_history[machine].append(status)\n",
    "\n",
    "            recent_statuses = self.machine_failure_history[machine][-5:]\n",
    "            consecutive_failures = all(s == 'Failed' for s in recent_statuses[-2:])\n",
    "            failure_ratio = recent_statuses.count('Failed') / len(recent_statuses)\n",
    "\n",
    "            if consecutive_failures or failure_ratio >= 0.6:\n",
    "                alert_msg = f\"‚ö†Ô∏è ALERT: {machine} is unreliable! ({failure_ratio*100:.0f}% failures)\"\n",
    "                alert_detail = {\n",
    "                    \"Machine_ID\": machine,\n",
    "                    \"Affected_Job\": job_id,\n",
    "                    \"Alert_Time\": start_time,\n",
    "                    \"Alert_Message\": alert_msg\n",
    "                }\n",
    "                self.breakdown_alerts.append(alert_detail)\n",
    "\n",
    "                self.send_desktop_alert(alert_msg)\n",
    "\n",
    "                # Recommend replacement\n",
    "                job_row = self.df[self.df['Job_ID'] == job_id].iloc[0]\n",
    "                replacement_machine = self.recommend_replacement(machine, job_row)\n",
    "                print(f\"Recommended replacement for {machine}: {replacement_machine}\")\n",
    "\n",
    "    def save_model(self, filename='job_scheduling_model.pkl'):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Assuming df is your preprocessed DataFrame\n",
    "df = pd.read_csv(\"preprocessed_job_data.csv\")\n",
    "\n",
    "# Initialize the model\n",
    "model = JobSchedulingModel(df)\n",
    "\n",
    "# Track failures and get alerts\n",
    "model.track_machine_failures_and_recommendation()\n",
    "\n",
    "# Save the model\n",
    "model.save_model('job_scheduling_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052c37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Recommended replacement for M04: M02\n",
      "Recommended replacement for M04: M03\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M04: M01\n",
      "Recommended replacement for M01: M05\n",
      "Recommended replacement for M01: M04\n",
      "Recommended replacement for M01: M03\n",
      "Recommended replacement for M01: M03\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M05: M02\n",
      "Recommended replacement for M05: M01\n",
      "Recommended replacement for M05: M04\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M01: M02\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M03: M01\n",
      "Recommended replacement for M01: M04\n",
      "Recommended replacement for M01: M04\n",
      "Recommended replacement for M03: M01\n",
      "Recommended replacement for M04: M01\n",
      "Recommended replacement for M02: M01\n",
      "Recommended replacement for M03: M02\n",
      "Recommended replacement for M02: M04\n",
      "Recommended replacement for M02: M03\n",
      "Recommended replacement for M01: M05\n",
      "Recommended replacement for M01: M02\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and its state\n",
    "model.save_model('job_scheduling_model.pkl')\n",
    "\n",
    "# Load the saved model\n",
    "with open('job_scheduling_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Use the loaded model\n",
    "loaded_model.track_machine_failures_and_recommendation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef31537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "# Core function\n",
    "def process_jobs(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert date columns\n",
    "    for col in ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Add Calculated Durations if not present\n",
    "    df['Calculated_Scheduled_Duration'] = (df['Scheduled_End'] - df['Scheduled_Start']).dt.total_seconds() / 3600\n",
    "    df['Calculated_Actual_Duration'] = (df['Actual_End'] - df['Actual_Start']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Identify breakdowns: jobs with 'Failed' or NaT in 'Actual_End'\n",
    "    breakdowns = df[df['Job_Status'].str.contains('Failed|Delayed', na=False)].copy()\n",
    "\n",
    "    breakdowns['Alert_Message'] = breakdowns.apply(\n",
    "        lambda row: f\"Machine {row['Machine_ID']} failed during Job {row['Job_ID']}\", axis=1\n",
    "    )\n",
    "\n",
    "    # Recommend replacements\n",
    "    def recommend_replacement(row):\n",
    "        same_ops = df[\n",
    "            (df['Operation_Type'] == row['Operation_Type']) &\n",
    "            (df['Machine_ID'] != row['Machine_ID']) &\n",
    "            (df['Machine_Availability'] > 85)\n",
    "        ].sort_values(by=['Machine_Availability', 'Energy_Consumption'], ascending=[False, True])\n",
    "        if not same_ops.empty:\n",
    "            return same_ops.iloc[0]['Machine_ID']\n",
    "        return \"‚ö†Ô∏è No Replacement Found\"\n",
    "\n",
    "    if not breakdowns.empty:\n",
    "        breakdowns['Suggested_Replacement'] = breakdowns.apply(recommend_replacement, axis=1)\n",
    "\n",
    "    # Gantt chart: visualize all jobs\n",
    "    chart_df = df.dropna(subset=['Scheduled_Start', 'Scheduled_End']).copy()\n",
    "    chart_df['Duration_Hours'] = chart_df['Calculated_Scheduled_Duration']\n",
    "    chart = px.timeline(chart_df,\n",
    "                        x_start=\"Scheduled_Start\", x_end=\"Scheduled_End\",\n",
    "                        y=\"Machine_ID\", color=\"Job_Status\",\n",
    "                        hover_name=\"Job_ID\", title=\"üìÖ Machine Job Schedule Timeline\")\n",
    "    chart.update_yaxes(autorange=\"reversed\")\n",
    "\n",
    "    # Return table view and chart\n",
    "    return df, breakdowns[['Job_ID', 'Machine_ID', 'Alert_Message', 'Suggested_Replacement']], chart\n",
    "\n",
    "# Gradio Interface\n",
    "app = gr.Interface(\n",
    "    fn=process_jobs,\n",
    "    inputs=gr.File(label=\"Upload Job Schedule CSV\"),\n",
    "    outputs=[\n",
    "        gr.Dataframe(label=\"üìã Full Job Schedule\"),\n",
    "        gr.Dataframe(label=\"üö® Breakdown Alerts & Replacements\"),\n",
    "        gr.Plot(label=\"üìà Job Timeline Visualization\")\n",
    "    ],\n",
    "    title=\"üîß Smart Job Scheduler & Breakdown Monitor\",\n",
    "    description=\"Upload your manufacturing job schedule CSV. Get visual insights, breakdown alerts, and machine recommendations!\"\n",
    ")\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ec5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da116107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
